{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from netCDF4 import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = '/home/heqin/Documents/dataAssimilationNumbaBigFile/wrfout_d02_2015-12-26_00_00_00'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class Dataset in module netCDF4._netCDF4:\n",
      "\n",
      "class Dataset(builtins.object)\n",
      " |  A netCDF `netCDF4.Dataset` is a collection of dimensions, groups, variables and\n",
      " |  attributes. Together they describe the meaning of data and relations among\n",
      " |  data fields stored in a netCDF file. See `netCDF4.Dataset.__init__` for more\n",
      " |  details.\n",
      " |  \n",
      " |  A list of attribute names corresponding to global netCDF attributes\n",
      " |  defined for the `netCDF4.Dataset` can be obtained with the\n",
      " |  `netCDF4.Dataset.ncattrs` method.\n",
      " |  These attributes can be created by assigning to an attribute of the\n",
      " |  `netCDF4.Dataset` instance. A dictionary containing all the netCDF attribute\n",
      " |  name/value pairs is provided by the `__dict__` attribute of a\n",
      " |  `netCDF4.Dataset` instance.\n",
      " |  \n",
      " |  The following class variables are read-only and should not be\n",
      " |  modified by the user.\n",
      " |  \n",
      " |  **`dimensions`**: The `dimensions` dictionary maps the names of\n",
      " |  dimensions defined for the `netCDF4.Group` or `netCDF4.Dataset` to instances of the\n",
      " |  `netCDF4.Dimension` class.\n",
      " |  \n",
      " |  **`variables`**: The `variables` dictionary maps the names of variables\n",
      " |  defined for this `netCDF4.Dataset` or `netCDF4.Group` to instances of the \n",
      " |  `netCDF4.Variable` class.\n",
      " |  \n",
      " |  **`groups`**: The groups dictionary maps the names of groups created for\n",
      " |  this `netCDF4.Dataset` or `netCDF4.Group` to instances of the `netCDF4.Group` class (the\n",
      " |  `netCDF4.Dataset` class is simply a special case of the `netCDF4.Group` class which\n",
      " |  describes the root group in the netCDF4 file).\n",
      " |  \n",
      " |  **`cmptypes`**: The `cmptypes` dictionary maps the names of\n",
      " |  compound types defined for the `netCDF4.Group` or `netCDF4.Dataset` to instances of the\n",
      " |  `netCDF4.CompoundType` class.\n",
      " |  \n",
      " |  **`vltypes`**: The `vltypes` dictionary maps the names of\n",
      " |  variable-length types defined for the `netCDF4.Group` or `netCDF4.Dataset` to instances \n",
      " |  of the `netCDF4.VLType` class.\n",
      " |  \n",
      " |  **`enumtypes`**: The `enumtypes` dictionary maps the names of\n",
      " |  Enum types defined for the `netCDF4.Group` or `netCDF4.Dataset` to instances \n",
      " |  of the `netCDF4.EnumType` class.\n",
      " |  \n",
      " |  **`data_model`**: `data_model` describes the netCDF\n",
      " |  data model version, one of `NETCDF3_CLASSIC`, `NETCDF4`,\n",
      " |  `NETCDF4_CLASSIC`, `NETCDF3_64BIT_OFFSET` or `NETCDF3_64BIT_DATA`.\n",
      " |  \n",
      " |  **`file_format`**: same as `data_model`, retained for backwards compatibility.\n",
      " |  \n",
      " |  **`disk_format`**: `disk_format` describes the underlying\n",
      " |  file format, one of `NETCDF3`, `HDF5`, `HDF4`,\n",
      " |  `PNETCDF`, `DAP2`, `DAP4` or `UNDEFINED`. Only available if using\n",
      " |  netcdf C library version >= 4.3.1, otherwise will always return\n",
      " |  `UNDEFINED`.\n",
      " |  \n",
      " |  **`parent`**: `parent` is a reference to the parent\n",
      " |  `netCDF4.Group` instance. `None` for the root group or `netCDF4.Dataset`\n",
      " |  instance.\n",
      " |  \n",
      " |  **`path`**: `path` shows the location of the `netCDF4.Group` in\n",
      " |  the `netCDF4.Dataset` in a unix directory format (the names of groups in the\n",
      " |  hierarchy separated by backslashes). A `netCDF4.Dataset` instance is the root\n",
      " |  group, so the path is simply `'/'`.\n",
      " |  \n",
      " |  **`keepweakref`**: If `True`, child Dimension and Variables objects only keep weak \n",
      " |  references to the parent Dataset or Group.\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __delattr__(self, name, /)\n",
      " |      Implement delattr(self, name).\n",
      " |  \n",
      " |  __enter__(...)\n",
      " |  \n",
      " |  __exit__(...)\n",
      " |  \n",
      " |  __getattr__(...)\n",
      " |  \n",
      " |  __getattribute__(self, name, /)\n",
      " |      Return getattr(self, name).\n",
      " |  \n",
      " |  __getitem__(self, key, /)\n",
      " |      Return self[key].\n",
      " |  \n",
      " |  __init__(...)\n",
      " |      **`__init__(self, filename, mode=\"r\", clobber=True, diskless=False,\n",
      " |      persist=False, keepweakref=False, format='NETCDF4')`**\n",
      " |      \n",
      " |      `netCDF4.Dataset` constructor.\n",
      " |      \n",
      " |      **`filename`**: Name of netCDF file to hold dataset. Can also\n",
      " |      be a python 3 pathlib instance or the URL of an OpenDAP dataset.  When memory is\n",
      " |      set this is just used to set the `filepath()`.\n",
      " |      \n",
      " |      **`mode`**: access mode. `r` means read-only; no data can be\n",
      " |      modified. `w` means write; a new file is created, an existing file with\n",
      " |      the same name is deleted. `a` and `r+` mean append (in analogy with\n",
      " |      serial files); an existing file is opened for reading and writing.\n",
      " |      Appending `s` to modes `w`, `r+` or `a` will enable unbuffered shared\n",
      " |      access to `NETCDF3_CLASSIC`, `NETCDF3_64BIT_OFFSET` or\n",
      " |      `NETCDF3_64BIT_DATA` formatted files.\n",
      " |      Unbuffered access may be useful even if you don't need shared\n",
      " |      access, since it may be faster for programs that don't access data\n",
      " |      sequentially. This option is ignored for `NETCDF4` and `NETCDF4_CLASSIC`\n",
      " |      formatted files.\n",
      " |      \n",
      " |      **`clobber`**: if `True` (default), opening a file with `mode='w'`\n",
      " |      will clobber an existing file with the same name.  if `False`, an\n",
      " |      exception will be raised if a file with the same name already exists.\n",
      " |      \n",
      " |      **`format`**: underlying file format (one of `'NETCDF4',\n",
      " |      'NETCDF4_CLASSIC', 'NETCDF3_CLASSIC'`, `'NETCDF3_64BIT_OFFSET'` or\n",
      " |      `'NETCDF3_64BIT_DATA'`.\n",
      " |      Only relevant if `mode = 'w'` (if `mode = 'r','a'` or `'r+'` the file format\n",
      " |      is automatically detected). Default `'NETCDF4'`, which means the data is\n",
      " |      stored in an HDF5 file, using netCDF 4 API features.  Setting\n",
      " |      `format='NETCDF4_CLASSIC'` will create an HDF5 file, using only netCDF 3\n",
      " |      compatible API features. netCDF 3 clients must be recompiled and linked\n",
      " |      against the netCDF 4 library to read files in `NETCDF4_CLASSIC` format.\n",
      " |      `'NETCDF3_CLASSIC'` is the classic netCDF 3 file format that does not\n",
      " |      handle 2+ Gb files. `'NETCDF3_64BIT_OFFSET'` is the 64-bit offset\n",
      " |      version of the netCDF 3 file format, which fully supports 2+ GB files, but\n",
      " |      is only compatible with clients linked against netCDF version 3.6.0 or\n",
      " |      later. `'NETCDF3_64BIT_DATA'` is the 64-bit data version of the netCDF 3\n",
      " |      file format, which supports 64-bit dimension sizes plus unsigned and\n",
      " |      64 bit integer data types, but is only compatible with clients linked against\n",
      " |      netCDF version 4.4.0 or later.\n",
      " |      \n",
      " |      **`diskless`**: If `True`, create diskless (in memory) file.  \n",
      " |      This is an experimental feature added to the C library after the\n",
      " |      netcdf-4.2 release.\n",
      " |      \n",
      " |      **`persist`**: if `diskless=True`, persist file to disk when closed\n",
      " |      (default `False`).\n",
      " |      \n",
      " |      **`keepweakref`**: if `True`, child Dimension and Variable instances will keep weak\n",
      " |      references to the parent Dataset or Group object.  Default is `False`, which\n",
      " |      means strong references will be kept.  Having Dimension and Variable instances\n",
      " |      keep a strong reference to the parent Dataset instance, which in turn keeps a\n",
      " |      reference to child Dimension and Variable instances, creates circular references.\n",
      " |      Circular references complicate garbage collection, which may mean increased\n",
      " |      memory usage for programs that create may Dataset instances with lots of\n",
      " |      Variables. It also will result in the Dataset object never being deleted, which\n",
      " |      means it may keep open files alive as well. Setting `keepweakref=True` allows\n",
      " |      Dataset instances to be garbage collected as soon as they go out of scope, potentially\n",
      " |      reducing memory usage and open file handles.  However, in many cases this is not\n",
      " |      desirable, since the associated Variable instances may still be needed, but are\n",
      " |      rendered unusable when the parent Dataset instance is garbage collected.\n",
      " |      \n",
      " |      **`memory`**: if not `None`, open file with contents taken from this block of memory.\n",
      " |      Must be a sequence of bytes.  Note this only works with \"r\" mode.\n",
      " |      \n",
      " |      **`encoding`**: encoding used to encode filename string into bytes.\n",
      " |      Default is None (`sys.getdefaultfileencoding()` is used).\n",
      " |      \n",
      " |      **`parallel`**: open for parallel access using MPI (requires mpi4py and\n",
      " |      parallel-enabled netcdf-c and hdf5 libraries).  Default is `False`. If\n",
      " |      `True`, `comm` and `info` kwargs may also be specified.\n",
      " |      \n",
      " |      **`comm`**: MPI_Comm object for parallel access. Default `None`, which\n",
      " |      means MPI_COMM_WORLD will be used.  Ignored if `parallel=False`.\n",
      " |      \n",
      " |      **`info`**: MPI_Info object for parallel access. Default `None`, which\n",
      " |      means MPI_INFO_NULL will be used.  Ignored if `parallel=False`.\n",
      " |  \n",
      " |  __new__(*args, **kwargs) from builtins.type\n",
      " |      Create and return a new object.  See help(type) for accurate signature.\n",
      " |  \n",
      " |  __reduce__(...)\n",
      " |      helper for pickle\n",
      " |  \n",
      " |  __repr__(self, /)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __setattr__(self, name, value, /)\n",
      " |      Implement setattr(self, name, value).\n",
      " |  \n",
      " |  __unicode__(...)\n",
      " |  \n",
      " |  close(...)\n",
      " |      **`close(self)`**\n",
      " |      \n",
      " |      Close the Dataset.\n",
      " |  \n",
      " |  createCompoundType(...)\n",
      " |      **`createCompoundType(self, datatype, datatype_name)`**\n",
      " |      \n",
      " |      Creates a new compound data type named `datatype_name` from the numpy\n",
      " |      dtype object `datatype`.\n",
      " |      \n",
      " |      ***Note***: If the new compound data type contains other compound data types\n",
      " |      (i.e. it is a 'nested' compound type, where not all of the elements\n",
      " |      are homogeneous numeric data types), then the 'inner' compound types **must** be\n",
      " |      created first.\n",
      " |      \n",
      " |      The return value is the `netCDF4.CompoundType` class instance describing the new\n",
      " |      datatype.\n",
      " |  \n",
      " |  createDimension(...)\n",
      " |      **`createDimension(self, dimname, size=None)`**\n",
      " |      \n",
      " |      Creates a new dimension with the given `dimname` and `size`.\n",
      " |      \n",
      " |      `size` must be a positive integer or `None`, which stands for\n",
      " |      \"unlimited\" (default is `None`). Specifying a size of 0 also\n",
      " |      results in an unlimited dimension. The return value is the `netCDF4.Dimension`\n",
      " |      class instance describing the new dimension.  To determine the current\n",
      " |      maximum size of the dimension, use the `len` function on the `netCDF4.Dimension`\n",
      " |      instance. To determine if a dimension is 'unlimited', use the\n",
      " |      `netCDF4.Dimension.isunlimited` method of the `netCDF4.Dimension` instance.\n",
      " |  \n",
      " |  createEnumType(...)\n",
      " |      **`createEnumType(self, datatype, datatype_name, enum_dict)`**\n",
      " |      \n",
      " |      Creates a new Enum data type named `datatype_name` from a numpy\n",
      " |      integer dtype object `datatype`, and a python dictionary\n",
      " |      defining the enum fields and values.\n",
      " |      \n",
      " |      The return value is the `netCDF4.EnumType` class instance describing the new\n",
      " |      datatype.\n",
      " |  \n",
      " |  createGroup(...)\n",
      " |      **`createGroup(self, groupname)`**\n",
      " |      \n",
      " |      Creates a new `netCDF4.Group` with the given `groupname`.\n",
      " |      \n",
      " |      If `groupname` is specified as a path, using forward slashes as in unix to\n",
      " |      separate components, then intermediate groups will be created as necessary \n",
      " |      (analogous to `mkdir -p` in unix).  For example,\n",
      " |      `createGroup('/GroupA/GroupB/GroupC')` will create `GroupA`,\n",
      " |      `GroupA/GroupB`, and `GroupA/GroupB/GroupC`, if they don't already exist.\n",
      " |      If the specified path describes a group that already exists, no error is\n",
      " |      raised.\n",
      " |      \n",
      " |      The return value is a `netCDF4.Group` class instance.\n",
      " |  \n",
      " |  createVLType(...)\n",
      " |      **`createVLType(self, datatype, datatype_name)`**\n",
      " |      \n",
      " |      Creates a new VLEN data type named `datatype_name` from a numpy\n",
      " |      dtype object `datatype`.\n",
      " |      \n",
      " |      The return value is the `netCDF4.VLType` class instance describing the new\n",
      " |      datatype.\n",
      " |  \n",
      " |  createVariable(...)\n",
      " |      **`createVariable(self, varname, datatype, dimensions=(), zlib=False,\n",
      " |      complevel=4, shuffle=True, fletcher32=False, contiguous=False, chunksizes=None,\n",
      " |      endian='native', least_significant_digit=None, fill_value=None)`**\n",
      " |      \n",
      " |      Creates a new variable with the given `varname`, `datatype`, and\n",
      " |      `dimensions`. If dimensions are not given, the variable is assumed to be\n",
      " |      a scalar.\n",
      " |      \n",
      " |      If `varname` is specified as a path, using forward slashes as in unix to\n",
      " |      separate components, then intermediate groups will be created as necessary \n",
      " |      For example, `createVariable('/GroupA/GroupB/VarC', float, ('x','y'))` will create groups `GroupA`\n",
      " |      and `GroupA/GroupB`, plus the variable `GroupA/GroupB/VarC`, if the preceding\n",
      " |      groups don't already exist.\n",
      " |      \n",
      " |      The `datatype` can be a numpy datatype object, or a string that describes\n",
      " |      a numpy dtype object (like the `dtype.str` attribute of a numpy array).\n",
      " |      Supported specifiers include: `'S1' or 'c' (NC_CHAR), 'i1' or 'b' or 'B'\n",
      " |      (NC_BYTE), 'u1' (NC_UBYTE), 'i2' or 'h' or 's' (NC_SHORT), 'u2'\n",
      " |      (NC_USHORT), 'i4' or 'i' or 'l' (NC_INT), 'u4' (NC_UINT), 'i8' (NC_INT64),\n",
      " |      'u8' (NC_UINT64), 'f4' or 'f' (NC_FLOAT), 'f8' or 'd' (NC_DOUBLE)`.\n",
      " |      `datatype` can also be a `netCDF4.CompoundType` instance\n",
      " |      (for a structured, or compound array), a `netCDF4.VLType` instance\n",
      " |      (for a variable-length array), or the python `str` builtin\n",
      " |      (for a variable-length string array). Numpy string and unicode datatypes with\n",
      " |      length greater than one are aliases for `str`.\n",
      " |      \n",
      " |      Data from netCDF variables is presented to python as numpy arrays with\n",
      " |      the corresponding data type.\n",
      " |      \n",
      " |      `dimensions` must be a tuple containing dimension names (strings) that\n",
      " |      have been defined previously using `netCDF4.Dataset.createDimension`. The default value\n",
      " |      is an empty tuple, which means the variable is a scalar.\n",
      " |      \n",
      " |      If the optional keyword `zlib` is `True`, the data will be compressed in\n",
      " |      the netCDF file using gzip compression (default `False`).\n",
      " |      \n",
      " |      The optional keyword `complevel` is an integer between 1 and 9 describing\n",
      " |      the level of compression desired (default 4). Ignored if `zlib=False`.\n",
      " |      \n",
      " |      If the optional keyword `shuffle` is `True`, the HDF5 shuffle filter\n",
      " |      will be applied before compressing the data (default `True`).  This\n",
      " |      significantly improves compression. Default is `True`. Ignored if\n",
      " |      `zlib=False`.\n",
      " |      \n",
      " |      If the optional keyword `fletcher32` is `True`, the Fletcher32 HDF5\n",
      " |      checksum algorithm is activated to detect errors. Default `False`.\n",
      " |      \n",
      " |      If the optional keyword `contiguous` is `True`, the variable data is\n",
      " |      stored contiguously on disk.  Default `False`. Setting to `True` for\n",
      " |      a variable with an unlimited dimension will trigger an error.\n",
      " |      \n",
      " |      The optional keyword `chunksizes` can be used to manually specify the\n",
      " |      HDF5 chunksizes for each dimension of the variable. A detailed\n",
      " |      discussion of HDF chunking and I/O performance is available\n",
      " |      [here](http://www.hdfgroup.org/HDF5/doc/H5.user/Chunking.html).\n",
      " |      Basically, you want the chunk size for each dimension to match as\n",
      " |      closely as possible the size of the data block that users will read\n",
      " |      from the file.  `chunksizes` cannot be set if `contiguous=True`.\n",
      " |      \n",
      " |      The optional keyword `endian` can be used to control whether the\n",
      " |      data is stored in little or big endian format on disk. Possible\n",
      " |      values are `little, big` or `native` (default). The library\n",
      " |      will automatically handle endian conversions when the data is read,\n",
      " |      but if the data is always going to be read on a computer with the\n",
      " |      opposite format as the one used to create the file, there may be\n",
      " |      some performance advantage to be gained by setting the endian-ness.\n",
      " |      \n",
      " |      The `zlib, complevel, shuffle, fletcher32, contiguous, chunksizes` and `endian`\n",
      " |      keywords are silently ignored for netCDF 3 files that do not use HDF5.\n",
      " |      \n",
      " |      The optional keyword `fill_value` can be used to override the default\n",
      " |      netCDF `_FillValue` (the value that the variable gets filled with before\n",
      " |      any data is written to it, defaults given in `netCDF4.default_fillvals`).\n",
      " |      If fill_value is set to `False`, then the variable is not pre-filled.\n",
      " |      \n",
      " |      If the optional keyword parameter `least_significant_digit` is\n",
      " |      specified, variable data will be truncated (quantized). In conjunction\n",
      " |      with `zlib=True` this produces 'lossy', but significantly more\n",
      " |      efficient compression. For example, if `least_significant_digit=1`,\n",
      " |      data will be quantized using `numpy.around(scale*data)/scale`, where\n",
      " |      scale = 2**bits, and bits is determined so that a precision of 0.1 is\n",
      " |      retained (in this case bits=4). From the \n",
      " |      [PSD metadata conventions](http://www.esrl.noaa.gov/psd/data/gridded/conventions/cdc_netcdf_standard.shtml):\n",
      " |      \"least_significant_digit -- power of ten of the smallest decimal place\n",
      " |      in unpacked data that is a reliable value.\" Default is `None`, or no\n",
      " |      quantization, or 'lossless' compression.\n",
      " |      \n",
      " |      When creating variables in a `NETCDF4` or `NETCDF4_CLASSIC` formatted file,\n",
      " |      HDF5 creates something called a 'chunk cache' for each variable.  The\n",
      " |      default size of the chunk cache may be large enough to completely fill\n",
      " |      available memory when creating thousands of variables.  The optional\n",
      " |      keyword `chunk_cache` allows you to reduce (or increase) the size of\n",
      " |      the default chunk cache when creating a variable.  The setting only\n",
      " |      persists as long as the Dataset is open - you can use the set_var_chunk_cache\n",
      " |      method to change it the next time the Dataset is opened.\n",
      " |      Warning - messing with this parameter can seriously degrade performance.\n",
      " |      \n",
      " |      The return value is the `netCDF4.Variable` class instance describing the new\n",
      " |      variable.\n",
      " |      \n",
      " |      A list of names corresponding to netCDF variable attributes can be\n",
      " |      obtained with the `netCDF4.Variable` method `netCDF4.Variable.ncattrs`. A dictionary\n",
      " |      containing all the netCDF attribute name/value pairs is provided by\n",
      " |      the `__dict__` attribute of a `netCDF4.Variable` instance.\n",
      " |      \n",
      " |      `netCDF4.Variable` instances behave much like array objects. Data can be\n",
      " |      assigned to or retrieved from a variable with indexing and slicing\n",
      " |      operations on the `netCDF4.Variable` instance. A `netCDF4.Variable` instance has six\n",
      " |      Dataset standard attributes: `dimensions, dtype, shape, ndim, name` and\n",
      " |      `least_significant_digit`. Application programs should never modify\n",
      " |      these attributes. The `dimensions` attribute is a tuple containing the\n",
      " |      names of the dimensions associated with this variable. The `dtype`\n",
      " |      attribute is a string describing the variable's data type (`i4, f8,\n",
      " |      S1,` etc). The `shape` attribute is a tuple describing the current\n",
      " |      sizes of all the variable's dimensions. The `name` attribute is a\n",
      " |      string containing the name of the Variable instance.\n",
      " |      The `least_significant_digit`\n",
      " |      attributes describes the power of ten of the smallest decimal place in\n",
      " |      the data the contains a reliable value.  assigned to the `netCDF4.Variable`\n",
      " |      instance. If `None`, the data is not truncated. The `ndim` attribute\n",
      " |      is the number of variable dimensions.\n",
      " |  \n",
      " |  delncattr(...)\n",
      " |      **`delncattr(self,name,value)`**\n",
      " |      \n",
      " |      delete a netCDF dataset or group attribute.  Use if you need to delete a\n",
      " |      netCDF attribute with the same name as one of the reserved python\n",
      " |      attributes.\n",
      " |  \n",
      " |  filepath(...)\n",
      " |      **`filepath(self,encoding=None)`**\n",
      " |      \n",
      " |      Get the file system path (or the opendap URL) which was used to\n",
      " |      open/create the Dataset. Requires netcdf >= 4.1.2.  The path\n",
      " |      is decoded into a string using `sys.getfilesystemencoding()` by default, this can be\n",
      " |      changed using the `encoding` kwarg.\n",
      " |  \n",
      " |  get_variables_by_attributes(...)\n",
      " |      **`get_variables_by_attribute(self, **kwargs)`**\n",
      " |      \n",
      " |      Returns a list of variables that match specific conditions.\n",
      " |      \n",
      " |      Can pass in key=value parameters and variables are returned that\n",
      " |      contain all of the matches. For example, \n",
      " |      \n",
      " |          :::python\n",
      " |          >>> # Get variables with x-axis attribute.\n",
      " |          >>> vs = nc.get_variables_by_attributes(axis='X')\n",
      " |          >>> # Get variables with matching \"standard_name\" attribute\n",
      " |          >>> vs = nc.get_variables_by_attributes(standard_name='northward_sea_water_velocity')\n",
      " |      \n",
      " |      Can pass in key=callable parameter and variables are returned if the\n",
      " |      callable returns True.  The callable should accept a single parameter,\n",
      " |      the attribute value.  None is given as the attribute value when the\n",
      " |      attribute does not exist on the variable. For example,\n",
      " |      \n",
      " |          :::python\n",
      " |          >>> # Get Axis variables\n",
      " |          >>> vs = nc.get_variables_by_attributes(axis=lambda v: v in ['X', 'Y', 'Z', 'T'])\n",
      " |          >>> # Get variables that don't have an \"axis\" attribute\n",
      " |          >>> vs = nc.get_variables_by_attributes(axis=lambda v: v is None)\n",
      " |          >>> # Get variables that have a \"grid_mapping\" attribute\n",
      " |          >>> vs = nc.get_variables_by_attributes(grid_mapping=lambda v: v is not None)\n",
      " |  \n",
      " |  getncattr(...)\n",
      " |      **`getncattr(self,name)`**\n",
      " |      \n",
      " |      retrieve a netCDF dataset or group attribute.\n",
      " |      Use if you need to get a netCDF attribute with the same\n",
      " |      name as one of the reserved python attributes.\n",
      " |      \n",
      " |      option kwarg `encoding` can be used to specify the\n",
      " |      character encoding of a string attribute (default is `utf-8`).\n",
      " |  \n",
      " |  isopen(...)\n",
      " |      **`close(self)`**\n",
      " |      \n",
      " |      is the Dataset open or closed?\n",
      " |  \n",
      " |  ncattrs(...)\n",
      " |      **`ncattrs(self)`**\n",
      " |      \n",
      " |      return netCDF global attribute names for this `netCDF4.Dataset` or `netCDF4.Group` in a list.\n",
      " |  \n",
      " |  renameAttribute(...)\n",
      " |      **`renameAttribute(self, oldname, newname)`**\n",
      " |      \n",
      " |      rename a `netCDF4.Dataset` or `netCDF4.Group` attribute named `oldname` to `newname`.\n",
      " |  \n",
      " |  renameDimension(...)\n",
      " |      **`renameDimension(self, oldname, newname)`**\n",
      " |      \n",
      " |      rename a `netCDF4.Dimension` named `oldname` to `newname`.\n",
      " |  \n",
      " |  renameGroup(...)\n",
      " |      **`renameGroup(self, oldname, newname)`**\n",
      " |      \n",
      " |      rename a `netCDF4.Group` named `oldname` to `newname` (requires netcdf >= 4.3.1).\n",
      " |  \n",
      " |  renameVariable(...)\n",
      " |      **`renameVariable(self, oldname, newname)`**\n",
      " |      \n",
      " |      rename a `netCDF4.Variable` named `oldname` to `newname`\n",
      " |  \n",
      " |  set_auto_chartostring(...)\n",
      " |      **`set_auto_chartostring(self, True_or_False)`**\n",
      " |      \n",
      " |      Call `netCDF4.Variable.set_auto_chartostring` for all variables contained in this `netCDF4.Dataset` or\n",
      " |      `netCDF4.Group`, as well as for all variables in all its subgroups.\n",
      " |      \n",
      " |      **`True_or_False`**: Boolean determining if automatic conversion of\n",
      " |      all character arrays <--> string arrays should be performed for \n",
      " |      character variables (variables of type `NC_CHAR` or `S1`) with the\n",
      " |      `_Encoding` attribute set.\n",
      " |      \n",
      " |      ***Note***: Calling this function only affects existing variables. Variables created\n",
      " |      after calling this function will follow the default behaviour.\n",
      " |  \n",
      " |  set_auto_mask(...)\n",
      " |      **`set_auto_mask(self, True_or_False)`**\n",
      " |      \n",
      " |      Call `netCDF4.Variable.set_auto_mask` for all variables contained in this `netCDF4.Dataset` or\n",
      " |      `netCDF4.Group`, as well as for all variables in all its subgroups.\n",
      " |      \n",
      " |      **`True_or_False`**: Boolean determining if automatic conversion to masked arrays\n",
      " |      shall be applied for all variables.\n",
      " |      \n",
      " |      ***Note***: Calling this function only affects existing variables. Variables created\n",
      " |      after calling this function will follow the default behaviour.\n",
      " |  \n",
      " |  set_auto_maskandscale(...)\n",
      " |      **`set_auto_maskandscale(self, True_or_False)`**\n",
      " |      \n",
      " |      Call `netCDF4.Variable.set_auto_maskandscale` for all variables contained in this `netCDF4.Dataset` or\n",
      " |      `netCDF4.Group`, as well as for all variables in all its subgroups.\n",
      " |      \n",
      " |      **`True_or_False`**: Boolean determining if automatic conversion to masked arrays\n",
      " |      and variable scaling shall be applied for all variables.\n",
      " |      \n",
      " |      ***Note***: Calling this function only affects existing variables. Variables created\n",
      " |      after calling this function will follow the default behaviour.\n",
      " |  \n",
      " |  set_auto_scale(...)\n",
      " |      **`set_auto_scale(self, True_or_False)`**\n",
      " |      \n",
      " |      Call `netCDF4.Variable.set_auto_scale` for all variables contained in this `netCDF4.Dataset` or\n",
      " |      `netCDF4.Group`, as well as for all variables in all its subgroups.\n",
      " |      \n",
      " |      **`True_or_False`**: Boolean determining if automatic variable scaling\n",
      " |      shall be applied for all variables.\n",
      " |      \n",
      " |      ***Note***: Calling this function only affects existing variables. Variables created\n",
      " |      after calling this function will follow the default behaviour.\n",
      " |  \n",
      " |  set_fill_off(...)\n",
      " |      **`set_fill_off(self)`**\n",
      " |      \n",
      " |      Sets the fill mode for a `netCDF4.Dataset` open for writing to `off`.\n",
      " |      \n",
      " |      This will prevent the data from being pre-filled with fill values, which\n",
      " |      may result in some performance improvements. However, you must then make\n",
      " |      sure the data is actually written before being read.\n",
      " |  \n",
      " |  set_fill_on(...)\n",
      " |      **`set_fill_on(self)`**\n",
      " |      \n",
      " |      Sets the fill mode for a `netCDF4.Dataset` open for writing to `on`.\n",
      " |      \n",
      " |      This causes data to be pre-filled with fill values. The fill values can be\n",
      " |      controlled by the variable's `_Fill_Value` attribute, but is usually\n",
      " |      sufficient to the use the netCDF default `_Fill_Value` (defined\n",
      " |      separately for each variable type). The default behavior of the netCDF\n",
      " |      library corresponds to `set_fill_on`.  Data which are equal to the\n",
      " |      `_Fill_Value` indicate that the variable was created, but never written\n",
      " |      to.\n",
      " |  \n",
      " |  setncattr(...)\n",
      " |      **`setncattr(self,name,value)`**\n",
      " |      \n",
      " |      set a netCDF dataset or group attribute using name,value pair.\n",
      " |      Use if you need to set a netCDF attribute with the\n",
      " |      with the same name as one of the reserved python attributes.\n",
      " |  \n",
      " |  setncattr_string(...)\n",
      " |      **`setncattr_string(self,name,value)`**\n",
      " |      \n",
      " |      set a netCDF dataset or group string attribute using name,value pair.\n",
      " |      Use if you need to ensure that a netCDF attribute is created with type\n",
      " |      `NC_STRING` if the file format is `NETCDF4`.\n",
      " |  \n",
      " |  setncatts(...)\n",
      " |      **`setncatts(self,attdict)`**\n",
      " |      \n",
      " |      set a bunch of netCDF dataset or group attributes at once using a python dictionary.\n",
      " |      This may be faster when setting a lot of attributes for a `NETCDF3`\n",
      " |      formatted file, since nc_redef/nc_enddef is not called in between setting\n",
      " |      each attribute\n",
      " |  \n",
      " |  sync(...)\n",
      " |      **`sync(self)`**\n",
      " |      \n",
      " |      Writes all buffered data in the `netCDF4.Dataset` to the disk file.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  __orthogonal_indexing__\n",
      " |  \n",
      " |  cmptypes\n",
      " |  \n",
      " |  data_model\n",
      " |  \n",
      " |  dimensions\n",
      " |  \n",
      " |  disk_format\n",
      " |  \n",
      " |  enumtypes\n",
      " |  \n",
      " |  file_format\n",
      " |  \n",
      " |  groups\n",
      " |  \n",
      " |  keepweakref\n",
      " |  \n",
      " |  parent\n",
      " |  \n",
      " |  path\n",
      " |  \n",
      " |  variables\n",
      " |  \n",
      " |  vltypes\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(Dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ncTemp = Dataset(file,'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<class 'netCDF4._netCDF4.Dataset'>\n",
       "root group (NETCDF3_64BIT_OFFSET data model, file format NETCDF3):\n",
       "    TITLE:  OUTPUT FROM *             PROGRAM:WRF/CHEM V3.5.1 MODEL\n",
       "    START_DATE: 2015-12-25_18:00:00\n",
       "    SIMULATION_START_DATE: 2015-12-25_18:00:00\n",
       "    WEST-EAST_GRID_DIMENSION: 97\n",
       "    SOUTH-NORTH_GRID_DIMENSION: 85\n",
       "    BOTTOM-TOP_GRID_DIMENSION: 31\n",
       "    DX: 15000.0\n",
       "    DY: 15000.0\n",
       "    STOCH_FORCE_OPT: 0\n",
       "    GRIDTYPE: C\n",
       "    DIFF_OPT: 1\n",
       "    KM_OPT: 4\n",
       "    DAMP_OPT: 0\n",
       "    DAMPCOEF: 0.2\n",
       "    KHDIF: 0.0\n",
       "    KVDIF: 0.0\n",
       "    MP_PHYSICS: 6\n",
       "    RA_LW_PHYSICS: 4\n",
       "    RA_SW_PHYSICS: 4\n",
       "    SF_SFCLAY_PHYSICS: 1\n",
       "    SF_SURFACE_PHYSICS: 2\n",
       "    BL_PBL_PHYSICS: 1\n",
       "    CU_PHYSICS: 5\n",
       "    SURFACE_INPUT_SOURCE: 1\n",
       "    SST_UPDATE: 0\n",
       "    GRID_FDDA: 0\n",
       "    GFDDA_INTERVAL_M: 0\n",
       "    GFDDA_END_H: 0\n",
       "    GRID_SFDDA: 0\n",
       "    SGFDDA_INTERVAL_M: 0\n",
       "    SGFDDA_END_H: 0\n",
       "    HYPSOMETRIC_OPT: 2\n",
       "    SF_URBAN_PHYSICS: 0\n",
       "    SHCU_PHYSICS: 0\n",
       "    MFSHCONV: 0\n",
       "    FEEDBACK: 1\n",
       "    SMOOTH_OPTION: 0\n",
       "    SWRAD_SCAT: 1.0\n",
       "    W_DAMPING: 1\n",
       "    DT: 60.0\n",
       "    RADT: 30.0\n",
       "    BLDT: 1.0\n",
       "    CUDT: 0.0\n",
       "    SWINT_OPT: 0\n",
       "    MOIST_ADV_OPT: 2\n",
       "    SCALAR_ADV_OPT: 2\n",
       "    TKE_ADV_OPT: 2\n",
       "    DIFF_6TH_OPT: 0\n",
       "    DIFF_6TH_FACTOR: 0.12\n",
       "    OBS_NUDGE_OPT: 0\n",
       "    BUCKET_MM: -1.0\n",
       "    BUCKET_J: -1.0\n",
       "    PREC_ACC_DT: 0.0\n",
       "    SF_OCEAN_PHYSICS: 0\n",
       "    ISFTCFLX: 0\n",
       "    ISHALLOW: 0\n",
       "    DFI_OPT: 0\n",
       "    WEST-EAST_PATCH_START_UNSTAG: 1\n",
       "    WEST-EAST_PATCH_END_UNSTAG: 96\n",
       "    WEST-EAST_PATCH_START_STAG: 1\n",
       "    WEST-EAST_PATCH_END_STAG: 97\n",
       "    SOUTH-NORTH_PATCH_START_UNSTAG: 1\n",
       "    SOUTH-NORTH_PATCH_END_UNSTAG: 84\n",
       "    SOUTH-NORTH_PATCH_START_STAG: 1\n",
       "    SOUTH-NORTH_PATCH_END_STAG: 85\n",
       "    BOTTOM-TOP_PATCH_START_UNSTAG: 1\n",
       "    BOTTOM-TOP_PATCH_END_UNSTAG: 30\n",
       "    BOTTOM-TOP_PATCH_START_STAG: 1\n",
       "    BOTTOM-TOP_PATCH_END_STAG: 31\n",
       "    GRID_ID: 2\n",
       "    PARENT_ID: 1\n",
       "    I_PARENT_START: 41\n",
       "    J_PARENT_START: 36\n",
       "    PARENT_GRID_RATIO: 3\n",
       "    CEN_LAT: 38.959415\n",
       "    CEN_LON: 115.02704\n",
       "    TRUELAT1: 30.0\n",
       "    TRUELAT2: 60.0\n",
       "    MOAD_CEN_LAT: 36.000004\n",
       "    STAND_LON: 109.4\n",
       "    POLE_LAT: 90.0\n",
       "    POLE_LON: 0.0\n",
       "    GMT: 0.0\n",
       "    JULYR: 2014\n",
       "    JULDAY: 273\n",
       "    MAP_PROJ: 1\n",
       "    MAP_PROJ_CHAR: Lambert Conformal\n",
       "    MMINLU: USGS\n",
       "    NUM_LAND_CAT: 24\n",
       "    ISWATER: 16\n",
       "    ISLAKE: -1\n",
       "    ISICE: 24\n",
       "    ISURBAN: 1\n",
       "    ISOILWATER: 14\n",
       "    dimensions(sizes): Time(1), DateStrLen(19), west_east(96), south_north(84), bottom_top(30), bottom_top_stag(31), soil_layers_stag(4), west_east_stag(97), south_north_stag(85), dust_erosion_dimension(3), vprm_vgcls(8), termite_vgcls(14)\n",
       "    variables(dimensions): |S1 \u001b[4mTimes\u001b[0m(Time,DateStrLen), float32 \u001b[4mXLAT\u001b[0m(Time,south_north,west_east), float32 \u001b[4mXLONG\u001b[0m(Time,south_north,west_east), float32 \u001b[4mLU_INDEX\u001b[0m(Time,south_north,west_east), float32 \u001b[4mZNU\u001b[0m(Time,bottom_top), float32 \u001b[4mZNW\u001b[0m(Time,bottom_top_stag), float32 \u001b[4mZS\u001b[0m(Time,soil_layers_stag), float32 \u001b[4mDZS\u001b[0m(Time,soil_layers_stag), float32 \u001b[4mVAR_SSO\u001b[0m(Time,south_north,west_east), float32 \u001b[4mLAP_HGT\u001b[0m(Time,south_north,west_east), float32 \u001b[4mU\u001b[0m(Time,bottom_top,south_north,west_east_stag), float32 \u001b[4mV\u001b[0m(Time,bottom_top,south_north_stag,west_east), float32 \u001b[4mW\u001b[0m(Time,bottom_top_stag,south_north,west_east), float32 \u001b[4mPH\u001b[0m(Time,bottom_top_stag,south_north,west_east), float32 \u001b[4mPHB\u001b[0m(Time,bottom_top_stag,south_north,west_east), float32 \u001b[4mT\u001b[0m(Time,bottom_top,south_north,west_east), float32 \u001b[4mHFX_FORCE\u001b[0m(Time), float32 \u001b[4mLH_FORCE\u001b[0m(Time), float32 \u001b[4mTSK_FORCE\u001b[0m(Time), float32 \u001b[4mHFX_FORCE_TEND\u001b[0m(Time), float32 \u001b[4mLH_FORCE_TEND\u001b[0m(Time), float32 \u001b[4mTSK_FORCE_TEND\u001b[0m(Time), float32 \u001b[4mMU\u001b[0m(Time,south_north,west_east), float32 \u001b[4mMUB\u001b[0m(Time,south_north,west_east), float32 \u001b[4mNEST_POS\u001b[0m(Time,south_north,west_east), float32 \u001b[4mP\u001b[0m(Time,bottom_top,south_north,west_east), float32 \u001b[4mALT\u001b[0m(Time,bottom_top,south_north,west_east), float32 \u001b[4mPB\u001b[0m(Time,bottom_top,south_north,west_east), float32 \u001b[4mFNM\u001b[0m(Time,bottom_top), float32 \u001b[4mFNP\u001b[0m(Time,bottom_top), float32 \u001b[4mRDNW\u001b[0m(Time,bottom_top), float32 \u001b[4mRDN\u001b[0m(Time,bottom_top), float32 \u001b[4mDNW\u001b[0m(Time,bottom_top), float32 \u001b[4mDN\u001b[0m(Time,bottom_top), float32 \u001b[4mCFN\u001b[0m(Time), float32 \u001b[4mCFN1\u001b[0m(Time), float32 \u001b[4mP_HYD\u001b[0m(Time,bottom_top,south_north,west_east), float32 \u001b[4mQ2\u001b[0m(Time,south_north,west_east), float32 \u001b[4mT2\u001b[0m(Time,south_north,west_east), float32 \u001b[4mTH2\u001b[0m(Time,south_north,west_east), float32 \u001b[4mPSFC\u001b[0m(Time,south_north,west_east), float32 \u001b[4mU10\u001b[0m(Time,south_north,west_east), float32 \u001b[4mV10\u001b[0m(Time,south_north,west_east), float32 \u001b[4mRDX\u001b[0m(Time), float32 \u001b[4mRDY\u001b[0m(Time), float32 \u001b[4mRESM\u001b[0m(Time), float32 \u001b[4mZETATOP\u001b[0m(Time), float32 \u001b[4mCF1\u001b[0m(Time), float32 \u001b[4mCF2\u001b[0m(Time), float32 \u001b[4mCF3\u001b[0m(Time), int32 \u001b[4mITIMESTEP\u001b[0m(Time), float32 \u001b[4mXTIME\u001b[0m(Time), float32 \u001b[4mQVAPOR\u001b[0m(Time,bottom_top,south_north,west_east), float32 \u001b[4mQCLOUD\u001b[0m(Time,bottom_top,south_north,west_east), float32 \u001b[4mQRAIN\u001b[0m(Time,bottom_top,south_north,west_east), float32 \u001b[4mQICE\u001b[0m(Time,bottom_top,south_north,west_east), float32 \u001b[4mQSNOW\u001b[0m(Time,bottom_top,south_north,west_east), float32 \u001b[4mQGRAUP\u001b[0m(Time,bottom_top,south_north,west_east), float32 \u001b[4mSHDMAX\u001b[0m(Time,south_north,west_east), float32 \u001b[4mSHDMIN\u001b[0m(Time,south_north,west_east), float32 \u001b[4mSNOALB\u001b[0m(Time,south_north,west_east), float32 \u001b[4mTSLB\u001b[0m(Time,soil_layers_stag,south_north,west_east), float32 \u001b[4mSMOIS\u001b[0m(Time,soil_layers_stag,south_north,west_east), float32 \u001b[4mSH2O\u001b[0m(Time,soil_layers_stag,south_north,west_east), float32 \u001b[4mSMCREL\u001b[0m(Time,soil_layers_stag,south_north,west_east), float32 \u001b[4mSEAICE\u001b[0m(Time,south_north,west_east), float32 \u001b[4mXICEM\u001b[0m(Time,south_north,west_east), float32 \u001b[4mSFROFF\u001b[0m(Time,south_north,west_east), float32 \u001b[4mUDROFF\u001b[0m(Time,south_north,west_east), int32 \u001b[4mIVGTYP\u001b[0m(Time,south_north,west_east), int32 \u001b[4mISLTYP\u001b[0m(Time,south_north,west_east), float32 \u001b[4mVEGFRA\u001b[0m(Time,south_north,west_east), float32 \u001b[4mGRDFLX\u001b[0m(Time,south_north,west_east), float32 \u001b[4mACGRDFLX\u001b[0m(Time,south_north,west_east), float32 \u001b[4mACSNOM\u001b[0m(Time,south_north,west_east), float32 \u001b[4mSNOW\u001b[0m(Time,south_north,west_east), float32 \u001b[4mSNOWH\u001b[0m(Time,south_north,west_east), float32 \u001b[4mCANWAT\u001b[0m(Time,south_north,west_east), float32 \u001b[4mSSTSK\u001b[0m(Time,south_north,west_east), float32 \u001b[4mCOSZEN\u001b[0m(Time,south_north,west_east), float32 \u001b[4mLAI\u001b[0m(Time,south_north,west_east), float32 \u001b[4mVAR\u001b[0m(Time,south_north,west_east), float32 \u001b[4mMAPFAC_M\u001b[0m(Time,south_north,west_east), float32 \u001b[4mMAPFAC_U\u001b[0m(Time,south_north,west_east_stag), float32 \u001b[4mMAPFAC_V\u001b[0m(Time,south_north_stag,west_east), float32 \u001b[4mMAPFAC_MX\u001b[0m(Time,south_north,west_east), float32 \u001b[4mMAPFAC_MY\u001b[0m(Time,south_north,west_east), float32 \u001b[4mMAPFAC_UX\u001b[0m(Time,south_north,west_east_stag), float32 \u001b[4mMAPFAC_UY\u001b[0m(Time,south_north,west_east_stag), float32 \u001b[4mMAPFAC_VX\u001b[0m(Time,south_north_stag,west_east), float32 \u001b[4mMF_VX_INV\u001b[0m(Time,south_north_stag,west_east), float32 \u001b[4mMAPFAC_VY\u001b[0m(Time,south_north_stag,west_east), float32 \u001b[4mF\u001b[0m(Time,south_north,west_east), float32 \u001b[4mE\u001b[0m(Time,south_north,west_east), float32 \u001b[4mSINALPHA\u001b[0m(Time,south_north,west_east), float32 \u001b[4mCOSALPHA\u001b[0m(Time,south_north,west_east), float32 \u001b[4mHGT\u001b[0m(Time,south_north,west_east), float32 \u001b[4mTSK\u001b[0m(Time,south_north,west_east), float32 \u001b[4mP_TOP\u001b[0m(Time), float32 \u001b[4mT00\u001b[0m(Time), float32 \u001b[4mP00\u001b[0m(Time), float32 \u001b[4mTLP\u001b[0m(Time), float32 \u001b[4mTISO\u001b[0m(Time), float32 \u001b[4mMAX_MSTFX\u001b[0m(Time), float32 \u001b[4mMAX_MSTFY\u001b[0m(Time), float32 \u001b[4mRAINC\u001b[0m(Time,south_north,west_east), float32 \u001b[4mRAINSH\u001b[0m(Time,south_north,west_east), float32 \u001b[4mRAINNC\u001b[0m(Time,south_north,west_east), float32 \u001b[4mSNOWNC\u001b[0m(Time,south_north,west_east), float32 \u001b[4mGRAUPELNC\u001b[0m(Time,south_north,west_east), float32 \u001b[4mHAILNC\u001b[0m(Time,south_north,west_east), float32 \u001b[4mREFL_10CM\u001b[0m(Time,bottom_top,south_north,west_east), float32 \u001b[4mCLDFRA\u001b[0m(Time,bottom_top,south_north,west_east), float32 \u001b[4mSWDOWN\u001b[0m(Time,south_north,west_east), float32 \u001b[4mGLW\u001b[0m(Time,south_north,west_east), float32 \u001b[4mSWNORM\u001b[0m(Time,south_north,west_east), float32 \u001b[4mSWDDIR\u001b[0m(Time,south_north,west_east), float32 \u001b[4mSWDDNI\u001b[0m(Time,south_north,west_east), float32 \u001b[4mSWDDIF\u001b[0m(Time,south_north,west_east), float32 \u001b[4mACSWUPT\u001b[0m(Time,south_north,west_east), float32 \u001b[4mACSWUPTC\u001b[0m(Time,south_north,west_east), float32 \u001b[4mACSWDNT\u001b[0m(Time,south_north,west_east), float32 \u001b[4mACSWDNTC\u001b[0m(Time,south_north,west_east), float32 \u001b[4mACSWUPB\u001b[0m(Time,south_north,west_east), float32 \u001b[4mACSWUPBC\u001b[0m(Time,south_north,west_east), float32 \u001b[4mACSWDNB\u001b[0m(Time,south_north,west_east), float32 \u001b[4mACSWDNBC\u001b[0m(Time,south_north,west_east), float32 \u001b[4mACLWUPT\u001b[0m(Time,south_north,west_east), float32 \u001b[4mACLWUPTC\u001b[0m(Time,south_north,west_east), float32 \u001b[4mACLWDNT\u001b[0m(Time,south_north,west_east), float32 \u001b[4mACLWDNTC\u001b[0m(Time,south_north,west_east), float32 \u001b[4mACLWUPB\u001b[0m(Time,south_north,west_east), float32 \u001b[4mACLWUPBC\u001b[0m(Time,south_north,west_east), float32 \u001b[4mACLWDNB\u001b[0m(Time,south_north,west_east), float32 \u001b[4mACLWDNBC\u001b[0m(Time,south_north,west_east), int32 \u001b[4mI_ACSWUPT\u001b[0m(Time,south_north,west_east), int32 \u001b[4mI_ACSWUPTC\u001b[0m(Time,south_north,west_east), int32 \u001b[4mI_ACSWDNT\u001b[0m(Time,south_north,west_east), int32 \u001b[4mI_ACSWDNTC\u001b[0m(Time,south_north,west_east), int32 \u001b[4mI_ACSWUPB\u001b[0m(Time,south_north,west_east), int32 \u001b[4mI_ACSWUPBC\u001b[0m(Time,south_north,west_east), int32 \u001b[4mI_ACSWDNB\u001b[0m(Time,south_north,west_east), int32 \u001b[4mI_ACSWDNBC\u001b[0m(Time,south_north,west_east), int32 \u001b[4mI_ACLWUPT\u001b[0m(Time,south_north,west_east), int32 \u001b[4mI_ACLWUPTC\u001b[0m(Time,south_north,west_east), int32 \u001b[4mI_ACLWDNT\u001b[0m(Time,south_north,west_east), int32 \u001b[4mI_ACLWDNTC\u001b[0m(Time,south_north,west_east), int32 \u001b[4mI_ACLWUPB\u001b[0m(Time,south_north,west_east), int32 \u001b[4mI_ACLWUPBC\u001b[0m(Time,south_north,west_east), int32 \u001b[4mI_ACLWDNB\u001b[0m(Time,south_north,west_east), int32 \u001b[4mI_ACLWDNBC\u001b[0m(Time,south_north,west_east), float32 \u001b[4mSWUPT\u001b[0m(Time,south_north,west_east), float32 \u001b[4mSWUPTC\u001b[0m(Time,south_north,west_east), float32 \u001b[4mSWDNT\u001b[0m(Time,south_north,west_east), float32 \u001b[4mSWDNTC\u001b[0m(Time,south_north,west_east), float32 \u001b[4mSWUPB\u001b[0m(Time,south_north,west_east), float32 \u001b[4mSWUPBC\u001b[0m(Time,south_north,west_east), float32 \u001b[4mSWDNB\u001b[0m(Time,south_north,west_east), float32 \u001b[4mSWDNBC\u001b[0m(Time,south_north,west_east), float32 \u001b[4mLWUPT\u001b[0m(Time,south_north,west_east), float32 \u001b[4mLWUPTC\u001b[0m(Time,south_north,west_east), float32 \u001b[4mLWDNT\u001b[0m(Time,south_north,west_east), float32 \u001b[4mLWDNTC\u001b[0m(Time,south_north,west_east), float32 \u001b[4mLWUPB\u001b[0m(Time,south_north,west_east), float32 \u001b[4mLWUPBC\u001b[0m(Time,south_north,west_east), float32 \u001b[4mLWDNB\u001b[0m(Time,south_north,west_east), float32 \u001b[4mLWDNBC\u001b[0m(Time,south_north,west_east), float32 \u001b[4mOLR\u001b[0m(Time,south_north,west_east), float32 \u001b[4mXLAT_U\u001b[0m(Time,south_north,west_east_stag), float32 \u001b[4mXLONG_U\u001b[0m(Time,south_north,west_east_stag), float32 \u001b[4mXLAT_V\u001b[0m(Time,south_north_stag,west_east), float32 \u001b[4mXLONG_V\u001b[0m(Time,south_north_stag,west_east), float32 \u001b[4mALBEDO\u001b[0m(Time,south_north,west_east), float32 \u001b[4mCLAT\u001b[0m(Time,south_north,west_east), float32 \u001b[4mALBBCK\u001b[0m(Time,south_north,west_east), float32 \u001b[4mEMISS\u001b[0m(Time,south_north,west_east), float32 \u001b[4mNOAHRES\u001b[0m(Time,south_north,west_east), float32 \u001b[4mFLX4\u001b[0m(Time,south_north,west_east), float32 \u001b[4mFVB\u001b[0m(Time,south_north,west_east), float32 \u001b[4mFBUR\u001b[0m(Time,south_north,west_east), float32 \u001b[4mFGSN\u001b[0m(Time,south_north,west_east), float32 \u001b[4mTMN\u001b[0m(Time,south_north,west_east), float32 \u001b[4mXLAND\u001b[0m(Time,south_north,west_east), float32 \u001b[4mUST\u001b[0m(Time,south_north,west_east), float32 \u001b[4mPBLH\u001b[0m(Time,south_north,west_east), float32 \u001b[4mHFX\u001b[0m(Time,south_north,west_east), float32 \u001b[4mQFX\u001b[0m(Time,south_north,west_east), float32 \u001b[4mLH\u001b[0m(Time,south_north,west_east), float32 \u001b[4mACHFX\u001b[0m(Time,south_north,west_east), float32 \u001b[4mACLHF\u001b[0m(Time,south_north,west_east), float32 \u001b[4mSNOWC\u001b[0m(Time,south_north,west_east), float32 \u001b[4mSR\u001b[0m(Time,south_north,west_east), int32 \u001b[4mSAVE_TOPO_FROM_REAL\u001b[0m(Time), float32 \u001b[4mEROD\u001b[0m(Time,dust_erosion_dimension,south_north,west_east), float32 \u001b[4mCLDFRA2\u001b[0m(Time,bottom_top,south_north,west_east), float32 \u001b[4mRAINPROD\u001b[0m(Time,bottom_top,south_north,west_east), float32 \u001b[4mEVAPPROD\u001b[0m(Time,bottom_top,south_north,west_east), float32 \u001b[4mEXTCOF55\u001b[0m(Time,bottom_top,south_north,west_east), float32 \u001b[4mPM2_5_DRY\u001b[0m(Time,bottom_top,south_north,west_east), float32 \u001b[4mPM10\u001b[0m(Time,bottom_top,south_north,west_east), float32 \u001b[4mDMS_0\u001b[0m(Time,south_north,west_east), float32 \u001b[4mRAD_VPRM\u001b[0m(Time,vprm_vgcls), float32 \u001b[4mLAMBDA_VPRM\u001b[0m(Time,vprm_vgcls), float32 \u001b[4mALPHA_VPRM\u001b[0m(Time,vprm_vgcls), float32 \u001b[4mRESP_VPRM\u001b[0m(Time,vprm_vgcls), float32 \u001b[4mBIOMT_PAR\u001b[0m(Time,termite_vgcls), float32 \u001b[4mEMIT_PAR\u001b[0m(Time,termite_vgcls), float32 \u001b[4mso2\u001b[0m(Time,bottom_top,south_north,west_east), float32 \u001b[4msulf\u001b[0m(Time,bottom_top,south_north,west_east), float32 \u001b[4mno2\u001b[0m(Time,bottom_top,south_north,west_east), float32 \u001b[4mno\u001b[0m(Time,bottom_top,south_north,west_east), float32 \u001b[4mo3\u001b[0m(Time,bottom_top,south_north,west_east), float32 \u001b[4mhno3\u001b[0m(Time,bottom_top,south_north,west_east), float32 \u001b[4mh2o2\u001b[0m(Time,bottom_top,south_north,west_east), float32 \u001b[4mald\u001b[0m(Time,bottom_top,south_north,west_east), float32 \u001b[4mhcho\u001b[0m(Time,bottom_top,south_north,west_east), float32 \u001b[4mop1\u001b[0m(Time,bottom_top,south_north,west_east), float32 \u001b[4mop2\u001b[0m(Time,bottom_top,south_north,west_east), float32 \u001b[4mora1\u001b[0m(Time,bottom_top,south_north,west_east), float32 \u001b[4mora2\u001b[0m(Time,bottom_top,south_north,west_east), float32 \u001b[4mnh3\u001b[0m(Time,bottom_top,south_north,west_east), float32 \u001b[4mn2o5\u001b[0m(Time,bottom_top,south_north,west_east), float32 \u001b[4mno3\u001b[0m(Time,bottom_top,south_north,west_east), float32 \u001b[4mpan\u001b[0m(Time,bottom_top,south_north,west_east), float32 \u001b[4meth\u001b[0m(Time,bottom_top,south_north,west_east), float32 \u001b[4mco\u001b[0m(Time,bottom_top,south_north,west_east), float32 \u001b[4mol2\u001b[0m(Time,bottom_top,south_north,west_east), float32 \u001b[4molt\u001b[0m(Time,bottom_top,south_north,west_east), float32 \u001b[4moli\u001b[0m(Time,bottom_top,south_north,west_east), float32 \u001b[4mtol\u001b[0m(Time,bottom_top,south_north,west_east), float32 \u001b[4mxyl\u001b[0m(Time,bottom_top,south_north,west_east), float32 \u001b[4mhono\u001b[0m(Time,bottom_top,south_north,west_east), float32 \u001b[4mhno4\u001b[0m(Time,bottom_top,south_north,west_east), float32 \u001b[4mket\u001b[0m(Time,bottom_top,south_north,west_east), float32 \u001b[4mmgly\u001b[0m(Time,bottom_top,south_north,west_east), float32 \u001b[4monit\u001b[0m(Time,bottom_top,south_north,west_east), float32 \u001b[4mcsl\u001b[0m(Time,bottom_top,south_north,west_east), float32 \u001b[4miso\u001b[0m(Time,bottom_top,south_north,west_east), float32 \u001b[4mho\u001b[0m(Time,bottom_top,south_north,west_east), float32 \u001b[4mho2\u001b[0m(Time,bottom_top,south_north,west_east), float32 \u001b[4mhcl\u001b[0m(Time,bottom_top,south_north,west_east), float32 \u001b[4mch3o2\u001b[0m(Time,bottom_top,south_north,west_east), float32 \u001b[4methp\u001b[0m(Time,bottom_top,south_north,west_east), float32 \u001b[4mch3oh\u001b[0m(Time,bottom_top,south_north,west_east), float32 \u001b[4mc2h5oh\u001b[0m(Time,bottom_top,south_north,west_east), float32 \u001b[4mpar\u001b[0m(Time,bottom_top,south_north,west_east), float32 \u001b[4mto2\u001b[0m(Time,bottom_top,south_north,west_east), float32 \u001b[4mcro\u001b[0m(Time,bottom_top,south_north,west_east), float32 \u001b[4mopen\u001b[0m(Time,bottom_top,south_north,west_east), float32 \u001b[4mop3\u001b[0m(Time,bottom_top,south_north,west_east), float32 \u001b[4mc2o3\u001b[0m(Time,bottom_top,south_north,west_east), float32 \u001b[4mro2\u001b[0m(Time,bottom_top,south_north,west_east), float32 \u001b[4mano2\u001b[0m(Time,bottom_top,south_north,west_east), float32 \u001b[4mnap\u001b[0m(Time,bottom_top,south_north,west_east), float32 \u001b[4mxo2\u001b[0m(Time,bottom_top,south_north,west_east), float32 \u001b[4mxpar\u001b[0m(Time,bottom_top,south_north,west_east), float32 \u001b[4misoprd\u001b[0m(Time,bottom_top,south_north,west_east), float32 \u001b[4misopp\u001b[0m(Time,bottom_top,south_north,west_east), float32 \u001b[4misopn\u001b[0m(Time,bottom_top,south_north,west_east), float32 \u001b[4misopo2\u001b[0m(Time,bottom_top,south_north,west_east), float32 \u001b[4mso4_a01\u001b[0m(Time,bottom_top,south_north,west_east), float32 \u001b[4mno3_a01\u001b[0m(Time,bottom_top,south_north,west_east), float32 \u001b[4mcl_a01\u001b[0m(Time,bottom_top,south_north,west_east), float32 \u001b[4mnh4_a01\u001b[0m(Time,bottom_top,south_north,west_east), float32 \u001b[4mna_a01\u001b[0m(Time,bottom_top,south_north,west_east), float32 \u001b[4moin_a01\u001b[0m(Time,bottom_top,south_north,west_east), float32 \u001b[4moc_a01\u001b[0m(Time,bottom_top,south_north,west_east), float32 \u001b[4mbc_a01\u001b[0m(Time,bottom_top,south_north,west_east), float32 \u001b[4mhysw_a01\u001b[0m(Time,bottom_top,south_north,west_east), float32 \u001b[4mwater_a01\u001b[0m(Time,bottom_top,south_north,west_east), float32 \u001b[4mnum_a01\u001b[0m(Time,bottom_top,south_north,west_east), float32 \u001b[4mso4_a02\u001b[0m(Time,bottom_top,south_north,west_east), float32 \u001b[4mno3_a02\u001b[0m(Time,bottom_top,south_north,west_east), float32 \u001b[4mcl_a02\u001b[0m(Time,bottom_top,south_north,west_east), float32 \u001b[4mnh4_a02\u001b[0m(Time,bottom_top,south_north,west_east), float32 \u001b[4mna_a02\u001b[0m(Time,bottom_top,south_north,west_east), float32 \u001b[4moin_a02\u001b[0m(Time,bottom_top,south_north,west_east), float32 \u001b[4moc_a02\u001b[0m(Time,bottom_top,south_north,west_east), float32 \u001b[4mbc_a02\u001b[0m(Time,bottom_top,south_north,west_east), float32 \u001b[4mhysw_a02\u001b[0m(Time,bottom_top,south_north,west_east), float32 \u001b[4mwater_a02\u001b[0m(Time,bottom_top,south_north,west_east), float32 \u001b[4mnum_a02\u001b[0m(Time,bottom_top,south_north,west_east), float32 \u001b[4mso4_a03\u001b[0m(Time,bottom_top,south_north,west_east), float32 \u001b[4mno3_a03\u001b[0m(Time,bottom_top,south_north,west_east), float32 \u001b[4mcl_a03\u001b[0m(Time,bottom_top,south_north,west_east), float32 \u001b[4mnh4_a03\u001b[0m(Time,bottom_top,south_north,west_east), float32 \u001b[4mna_a03\u001b[0m(Time,bottom_top,south_north,west_east), float32 \u001b[4moin_a03\u001b[0m(Time,bottom_top,south_north,west_east), float32 \u001b[4moc_a03\u001b[0m(Time,bottom_top,south_north,west_east), float32 \u001b[4mbc_a03\u001b[0m(Time,bottom_top,south_north,west_east), float32 \u001b[4mhysw_a03\u001b[0m(Time,bottom_top,south_north,west_east), float32 \u001b[4mwater_a03\u001b[0m(Time,bottom_top,south_north,west_east), float32 \u001b[4mnum_a03\u001b[0m(Time,bottom_top,south_north,west_east), float32 \u001b[4mso4_a04\u001b[0m(Time,bottom_top,south_north,west_east), float32 \u001b[4mno3_a04\u001b[0m(Time,bottom_top,south_north,west_east), float32 \u001b[4mcl_a04\u001b[0m(Time,bottom_top,south_north,west_east), float32 \u001b[4mnh4_a04\u001b[0m(Time,bottom_top,south_north,west_east), float32 \u001b[4mna_a04\u001b[0m(Time,bottom_top,south_north,west_east), float32 \u001b[4moin_a04\u001b[0m(Time,bottom_top,south_north,west_east), float32 \u001b[4moc_a04\u001b[0m(Time,bottom_top,south_north,west_east), float32 \u001b[4mbc_a04\u001b[0m(Time,bottom_top,south_north,west_east), float32 \u001b[4mhysw_a04\u001b[0m(Time,bottom_top,south_north,west_east), float32 \u001b[4mwater_a04\u001b[0m(Time,bottom_top,south_north,west_east), float32 \u001b[4mnum_a04\u001b[0m(Time,bottom_top,south_north,west_east), int32 \u001b[4mSEED1\u001b[0m(Time), int32 \u001b[4mSEED2\u001b[0m(Time), float32 \u001b[4mLANDMASK\u001b[0m(Time,south_north,west_east), float32 \u001b[4mSST\u001b[0m(Time,south_north,west_east)\n",
       "    groups: "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ncTemp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ncl-6.5.0",
   "language": "python",
   "name": "ncl-6.5.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
